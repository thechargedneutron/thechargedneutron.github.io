---
title: "Video-Mined Task Graphs for Keystep Recognition in Instructional Videos"
layout: post
<!-- date: 2016-01-23 22:10 -->
tag: vision
image: /assets/images/nus-logo.jpg
headerImage: false
projects: true
hidden: true # don't count this post in blog pagination
subtitle: Includes projects prior to May 2018
description: 
category: publication-ut
<!-- author: kumarashutosh -->
excerpt: "Neural Information Processing Systems (NeurIPS), December 2023"
excerpt2: <u>Kumar Ashutosh</u>, Santhosh Kumar Ramakrishnan, Triantafyllos Afouras, Kristen Grauman
paper_link: https://arxiv.org/abs/2307.08763
project_page: https://vision.cs.utexas.edu/projects/task_graph/
externalLink: false
year: year2017
image:
  feature: "only_task_graph.png"
---

Please refer to the project page: [https://vision.cs.utexas.edu/projects/task_graph/](https://vision.cs.utexas.edu/projects/task_graph/) and the paper: [https://arxiv.org/abs/2307.08763](https://arxiv.org/abs/2307.08763)

### Abstract &nbsp;

Procedural activity understanding requires perceiving human actions in terms of a broader task, where multiple keysteps are performed in sequence across a long video to reach a final goal state---such as the steps of a recipe or a DIY fix-it task.  Prior work largely treats keystep recognition in isolation of this broader structure, or else rigidly confines keysteps to align with a predefined sequential script.  We propose discovering a task graph automatically from how-to videos to represent probabilistically how people tend to execute keysteps, and then leverage this graph to regularize keystep recognition in novel videos.  On multiple datasets of real-world instructional videos, we show the impact: more reliable zero-shot keystep localization and improved video representation learning, exceeding the state of the art.