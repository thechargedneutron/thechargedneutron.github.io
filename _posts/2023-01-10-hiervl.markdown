---
title: "HierVL: Learning Hierarchical Video-Language Embeddings"
layout: post
<!-- date: 2016-01-23 22:10 -->
tag: vision
image: /assets/images/nus-logo.jpg
headerImage: false
projects: true
hidden: true # don't count this post in blog pagination
subtitle: Includes projects prior to May 2018
description: 
category: publication-ut
<!-- author: kumarashutosh -->
excerpt: "IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), June 2023"
excerpt2: <u>Kumar Ashutosh</u>, Rohit Girdhar, Lorenzo Torresani, Kristen Grauman
paper_link: https://arxiv.org/abs/2301.02311
project_page: https://vision.cs.utexas.edu/projects/hiervl/
externalLink: false
year: year2017
image:
  feature: "motivation_hiervl.jpg"
---

Please refer to the project page: [https://vision.cs.utexas.edu/projects/hiervl/](https://vision.cs.utexas.edu/projects/hiervl/) and the paper: [https://arxiv.org/abs/2301.02311](https://arxiv.org/abs/2301.02311)

### Abstract &nbsp;

Video-language embeddings are a promising avenue for injecting semantics into visual representations, but existing methods capture only short-term associations between seconds-long video clips and their accompanying text. We propose HierVL, a novel hierarchical video-language embedding that simultaneously accounts for both long-term and short-term associations. As training data, we take videos accompanied by timestamped text descriptions of human actions, together with a high-level text summary of the activity throughout the long video (as are available in Ego4D). We introduce a hierarchical contrastive training objective that encourages text-visual alignment at both the clip level and video level. While the clip-level constraints use the step-by-step descriptions to capture what is happening in that instant, the video-level constraints use the summary text to capture why it is happening, i.e., the broader context for the activity and the intent of the actor. Our hierarchical scheme yields a clip representation that outperforms its single-level counterpart as well as a long-term video representation that achieves SotA results on tasks requiring long-term video modeling. HierVL successfully transfers to multiple challenging downstream tasks (in EPIC-KITCHENS-100, Charades-Ego, HowTo100M) in both zero-shot and fine-tuned settings.